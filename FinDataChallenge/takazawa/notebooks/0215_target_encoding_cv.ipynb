{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# First Model\n",
    "\n",
    "In this notebook, we create a simple model using LightGBM. The features included in this model are:\n",
    "- all float (or int but not category) variables as it is:\n",
    "    - `RevLineCr`, `NoEmp`, `CreateJob`, `RetainedJob`, `ApprovalFY`. `DisbursementGross`, `GrAppv`, `SBA_Appv`\n",
    "- some categorical variables as it is:\n",
    "    - `NewExist`, `RevLineCr`, `LowDoc`, `UrbanRural`\n",
    "- Some date objects as daystamp:\n",
    "    - `DisbursementDate_daystamp`, `ApprovalDate_daystamp`\n",
    "- Some categorical varibles with coarse labeling:\n",
    "    - `FranchiseCode`(0,1,or others)\n",
    "- Some categorical variables with holdout target encoding:\n",
    "    - `Sector`, `State`, `BankState`\n",
    "- `Longitude`, `Latitude`: holdout target encoded with `HistGradientBoostingClassifier`\n",
    "\n",
    "Note that `City` is not used in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cat_encodings import target_encode_test, target_encode_smooth_test, target_encode_cols_smooth_test\n",
    "from clean_data import clean_data\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import numbers\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"edited_data/train_cleaned_geo.csv\", index_col=0)\n",
    "test = pd.read_csv(\"edited_data/test_cleaned_geo.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns used for training -> all_cols\n",
    "num_cols = ['NoEmp', 'CreateJob', 'RetainedJob', 'ApprovalFY', 'DisbursementGross', 'GrAppv', 'SBA_Appv']\n",
    "retained_cat_cols = ['NewExist', 'RevLineCr', 'LowDoc', 'UrbanRural']\n",
    "timestamp_cols = ['DisbursementDate_daystamp', 'ApprovalDate_daystamp']\n",
    "franchise_cols = ['FranchiseCode1', 'FranchiseCode0']\n",
    "target_encode_cols = ['Sector', 'State', 'BankState', 'FranchiseCode']\n",
    "target_encoded_cols = [item + \"_target\" for item in target_encode_cols]\n",
    "target_encode_smooth_cols = [\"longitude\", \"latitude\"]\n",
    "target_encoded_smooth_cols = ['location_target']\n",
    "location_cols = ['latitude', 'longitude']\n",
    "all_cols = num_cols + retained_cat_cols + timestamp_cols + franchise_cols + target_encoded_cols + location_cols + target_encoded_smooth_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas category for categorical vars\n",
    "for column in retained_cat_cols:\n",
    "    train[column] = train[column].astype(\"category\")\n",
    "    test[column] = test[column].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, val の分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train,train[\"MIS_Status\"], test_size=0.2, random_state=42, stratify=train['MIS_Status']) # stratifyした方がいいかも"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding for valid data\n",
    "\n",
    "trainの値を使って，testのtarget encodingをします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encode_cols = ['Sector', 'State', 'BankState', 'FranchiseCode']\n",
    "    \n",
    "# We can simply use training data to encode the test data\n",
    "for col in target_encode_cols:\n",
    "    X_val = target_encode_test(X_train, y_train, X_val, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for smooth data:\n",
    "X_val = target_encode_cols_smooth_test(X_train, y_train, X_val, [\"longitude\", \"latitude\"], \"location\")\n",
    "#X_val =target_encode_smooth_test(X_train, y_train, X_val, \"longitude\")\n",
    "#X_val =target_encode_smooth_test(X_train, y_train, X_val, \"latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding for train data\n",
    "\n",
    "CVの分け方と合うように，target encodingをしていきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1000)\n",
    "# for train\n",
    "kf_iter_train = kf.split(X_train, y_train)\n",
    "\n",
    "# create list of indices for training / test data to use for holdout target encoding\n",
    "folds_train = []\n",
    "for train_idx, test_idx in kf_iter_train:\n",
    "    folds_train.append((train_idx, test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trs = []; X_cvalids = []\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    X_tr, X_cvalid = X_train.iloc[train_indices], X_train.iloc[cvalid_indices]\n",
    "    y_tr, y_cvalid = y_train.iloc[train_indices], y_train.iloc[cvalid_indices]\n",
    "    for col in target_encode_cols:\n",
    "        X_tr = target_encode_test(X_cvalid, y_cvalid, X_tr, col)\n",
    "        X_cvalid = target_encode_test(X_tr, y_tr, X_cvalid, col)\n",
    "    X_tr = target_encode_cols_smooth_test(X_cvalid, y_cvalid, X_tr, [\"longitude\", \"latitude\"], \"location\")\n",
    "    X_cvalid = target_encode_cols_smooth_test(X_tr, y_tr, X_cvalid, [\"longitude\", \"latitude\"], \"location\")\n",
    "    # for col in target_encode_smooth_cols:\n",
    "    #     X_tr = target_encode_smooth_test(X_cvalid, y_cvalid, X_tr, col)\n",
    "    #     X_cvalid = target_encode_smooth_test(X_tr, y_tr, X_cvalid, col)\n",
    "    X_trs.append(X_tr[all_cols])\n",
    "    X_cvalids.append(X_cvalid[all_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6266666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['DisbursementDate'].isnull()]['MIS_Status'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoteennをスキップする時用\n",
    "y_trs = [None for i in range(5)]\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    y_trs[fold] = y_train.iloc[train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro F1 Score (with threshold included in the metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  f1_score\n",
    "def Macrof1(preds, eval_dataset):\n",
    "    y_true = eval_dataset.get_label()\n",
    "    max_score =0\n",
    "    for th in np.linspace(0.1,0.9,100):\n",
    "        y_pred = (preds>th).astype(int)\n",
    "        score = f1_score(y_true, y_pred, average='macro')\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "    return 'Macrof1', max_score, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold No. =  0\n",
      "[10]\tvalid_0's Macrof1: 0.681079\n",
      "[20]\tvalid_0's Macrof1: 0.68243\n",
      "[30]\tvalid_0's Macrof1: 0.685347\n",
      "[40]\tvalid_0's Macrof1: 0.685313\n",
      "[50]\tvalid_0's Macrof1: 0.684716\n",
      "[60]\tvalid_0's Macrof1: 0.682284\n",
      "[70]\tvalid_0's Macrof1: 0.682242\n",
      "[80]\tvalid_0's Macrof1: 0.680164\n",
      "[90]\tvalid_0's Macrof1: 0.680963\n",
      "[100]\tvalid_0's Macrof1: 0.68235\n",
      "now caluculating MacroF1 values .....\n",
      "fold 0 MacroF1: 0.6876402584155049\n",
      "fold No. =  1\n",
      "[10]\tvalid_0's Macrof1: 0.689282\n",
      "[20]\tvalid_0's Macrof1: 0.6931\n",
      "[30]\tvalid_0's Macrof1: 0.692598\n",
      "[40]\tvalid_0's Macrof1: 0.692592\n",
      "[50]\tvalid_0's Macrof1: 0.694833\n",
      "[60]\tvalid_0's Macrof1: 0.695501\n",
      "[70]\tvalid_0's Macrof1: 0.693943\n",
      "[80]\tvalid_0's Macrof1: 0.694385\n",
      "[90]\tvalid_0's Macrof1: 0.693278\n",
      "[100]\tvalid_0's Macrof1: 0.692398\n",
      "now caluculating MacroF1 values .....\n",
      "fold 1 MacroF1: 0.6959372776923907\n",
      "fold No. =  2\n",
      "[10]\tvalid_0's Macrof1: 0.675781\n",
      "[20]\tvalid_0's Macrof1: 0.677121\n",
      "[30]\tvalid_0's Macrof1: 0.678869\n",
      "[40]\tvalid_0's Macrof1: 0.684797\n",
      "[50]\tvalid_0's Macrof1: 0.68413\n",
      "[60]\tvalid_0's Macrof1: 0.684872\n",
      "[70]\tvalid_0's Macrof1: 0.683381\n",
      "[80]\tvalid_0's Macrof1: 0.683948\n",
      "[90]\tvalid_0's Macrof1: 0.682846\n",
      "[100]\tvalid_0's Macrof1: 0.682803\n",
      "now caluculating MacroF1 values .....\n",
      "fold 2 MacroF1: 0.6869127783742714\n",
      "fold No. =  3\n",
      "[10]\tvalid_0's Macrof1: 0.668785\n",
      "[20]\tvalid_0's Macrof1: 0.672597\n",
      "[30]\tvalid_0's Macrof1: 0.673953\n",
      "[40]\tvalid_0's Macrof1: 0.671736\n",
      "[50]\tvalid_0's Macrof1: 0.672572\n",
      "[60]\tvalid_0's Macrof1: 0.672719\n",
      "[70]\tvalid_0's Macrof1: 0.671117\n",
      "[80]\tvalid_0's Macrof1: 0.674853\n",
      "[90]\tvalid_0's Macrof1: 0.673854\n",
      "[100]\tvalid_0's Macrof1: 0.673777\n",
      "now caluculating MacroF1 values .....\n",
      "fold 3 MacroF1: 0.6750680955999133\n",
      "fold No. =  4\n",
      "[10]\tvalid_0's Macrof1: 0.684491\n",
      "[20]\tvalid_0's Macrof1: 0.68775\n",
      "[30]\tvalid_0's Macrof1: 0.690677\n",
      "[40]\tvalid_0's Macrof1: 0.688989\n",
      "[50]\tvalid_0's Macrof1: 0.688343\n",
      "[60]\tvalid_0's Macrof1: 0.689134\n",
      "[70]\tvalid_0's Macrof1: 0.687833\n",
      "[80]\tvalid_0's Macrof1: 0.686779\n",
      "[90]\tvalid_0's Macrof1: 0.687145\n",
      "[100]\tvalid_0's Macrof1: 0.687575\n",
      "now caluculating MacroF1 values .....\n",
      "fold 4 MacroF1: 0.691109221738671\n"
     ]
    }
   ],
   "source": [
    "valid_scores = []\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "boosters = []\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    X_tr = X_trs[fold]\n",
    "    X_cvalid = X_cvalids[fold]\n",
    "    y_tr = y_trs[fold]\n",
    "    y_cvalid = y_train.iloc[cvalid_indices]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "    lgb_eval = lgb.Dataset(X_cvalid, y_cvalid)\n",
    "\n",
    "    print(\"fold No. = \", fold)\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'None',  # Use custom to use the custom metric for evaluation\n",
    "    'verbose': -1,\n",
    "    'learning_rate':0.1,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets = lgb_eval,\n",
    "        num_boost_round = 100,\n",
    "        feval = Macrof1,\n",
    "        callbacks=[lgb.log_evaluation(10)],\n",
    "    )\n",
    "    \n",
    "    print(\"now caluculating MacroF1 values .....\")\n",
    "    name, score, _ = Macrof1(model.predict(X_cvalid), lgb_eval)\n",
    "    print(f'fold {fold} MacroF1: {score}')\n",
    "    valid_scores.append(score)\n",
    "\n",
    "    boosters.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold No. =  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's Macrof1: 0.681079\n",
      "[20]\tvalid_0's Macrof1: 0.68243\n",
      "[30]\tvalid_0's Macrof1: 0.685347\n",
      "[40]\tvalid_0's Macrof1: 0.685313\n",
      "[50]\tvalid_0's Macrof1: 0.684716\n",
      "[60]\tvalid_0's Macrof1: 0.682284\n",
      "[70]\tvalid_0's Macrof1: 0.682242\n",
      "[80]\tvalid_0's Macrof1: 0.680164\n",
      "[90]\tvalid_0's Macrof1: 0.680963\n",
      "[100]\tvalid_0's Macrof1: 0.68235\n",
      "now caluculating MacroF1 values .....\n",
      "fold 0 MacroF1: 0.6876402584155049\n",
      "fold No. =  1\n",
      "[10]\tvalid_0's Macrof1: 0.689282\n",
      "[20]\tvalid_0's Macrof1: 0.6931\n",
      "[30]\tvalid_0's Macrof1: 0.692598\n",
      "[40]\tvalid_0's Macrof1: 0.692592\n",
      "[50]\tvalid_0's Macrof1: 0.694833\n",
      "[60]\tvalid_0's Macrof1: 0.695501\n",
      "[70]\tvalid_0's Macrof1: 0.693943\n",
      "[80]\tvalid_0's Macrof1: 0.694385\n",
      "[90]\tvalid_0's Macrof1: 0.693278\n",
      "[100]\tvalid_0's Macrof1: 0.692398\n",
      "now caluculating MacroF1 values .....\n",
      "fold 1 MacroF1: 0.6959372776923907\n",
      "fold No. =  2\n",
      "[10]\tvalid_0's Macrof1: 0.675781\n",
      "[20]\tvalid_0's Macrof1: 0.677121\n",
      "[30]\tvalid_0's Macrof1: 0.678869\n",
      "[40]\tvalid_0's Macrof1: 0.684797\n",
      "[50]\tvalid_0's Macrof1: 0.68413\n",
      "[60]\tvalid_0's Macrof1: 0.684872\n",
      "[70]\tvalid_0's Macrof1: 0.683381\n",
      "[80]\tvalid_0's Macrof1: 0.683948\n",
      "[90]\tvalid_0's Macrof1: 0.682846\n"
     ]
    }
   ],
   "source": [
    "valid_scores = []\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "boosters = []\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    X_tr = X_trs[fold]\n",
    "    X_cvalid = X_cvalids[fold]\n",
    "    y_tr = y_trs[fold]\n",
    "    y_cvalid = y_train.iloc[cvalid_indices]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "    lgb_eval = lgb.Dataset(X_cvalid, y_cvalid)\n",
    "\n",
    "    print(\"fold No. = \", fold)\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'None',  # Use custom to use the custom metric for evaluation\n",
    "    'verbose': -1,\n",
    "    'learning_rate':0.1,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets = lgb_eval,\n",
    "        num_boost_round = 100,\n",
    "        feval = Macrof1,\n",
    "        callbacks=[lgb.log_evaluation(10)],\n",
    "    )\n",
    "    \n",
    "    print(\"now caluculating MacroF1 values .....\")\n",
    "    name, score, _ = Macrof1(model.predict(X_cvalid), lgb_eval)\n",
    "    print(f'fold {fold} MacroF1: {score}')\n",
    "    valid_scores.append(score)\n",
    "\n",
    "    boosters.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6858837177977554,\n",
       " 0.6952863920108225,\n",
       " 0.6842453803525832,\n",
       " 0.6730346469061509,\n",
       " 0.6886688530417936]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check scores with valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encode all training data\n",
    "target_encode_cols = ['Sector', 'State', 'BankState', 'FranchiseCode']\n",
    "    \n",
    "# We can simply use training data to encode the test data\n",
    "for col in target_encode_cols:\n",
    "    X_train = target_encode_test(X_train, y_train, X_train, col)\n",
    "# for smooth data:\n",
    "X_train = target_encode_cols_smooth_test(X_train, y_train, X_train, [\"longitude\", \"latitude\"], \"location\")\n",
    "#X_val =target_encode_smooth_test(X_train, y_train, X_val, \"longitude\")\n",
    "#X_val =target_encode_smooth_test(X_train, y_train, X_val, \"latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "preds = np.array([item.predict(X_train[all_cols]) for item in boosters])\n",
    "clf = LogisticRegression(random_state=0).fit(preds.T, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97920583 0.7772076  0.93469781 ... 0.96566192 0.8488847  0.9497741 ]\n",
      " [0.97560263 0.8659089  0.94050981 ... 0.94704968 0.894372   0.93765919]\n",
      " [0.97809229 0.90228615 0.92094027 ... 0.95643572 0.76844993 0.95860478]\n",
      " [0.97964122 0.78037028 0.9089544  ... 0.9599944  0.86564927 0.96976384]\n",
      " [0.97263074 0.84098256 0.92867224 ... 0.94723998 0.86507642 0.95421878]]\n"
     ]
    }
   ],
   "source": [
    "#pred_average = np.mean([item.predict(X_val[all_cols]) for item in boosters], axis=0)\n",
    "pred_test = np.array([item.predict(X_val[all_cols]) for item in boosters])\n",
    "print(pred_test)\n",
    "pred_average = clf.predict_proba(pred_test.T)[:,1]\n",
    "\n",
    "test_prediction = (pred_average > np.quantile(pred_average, 0.1)).astype(int) # ここはもう少し良い選び方があるはずです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741911970338366"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, test_prediction, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB training with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1000)\n",
    "# for train\n",
    "kf_iter_train = kf.split(train, train['MIS_Status'])\n",
    "\n",
    "# create list of indices for training / test data to use for holdout target encoding\n",
    "folds_train = []\n",
    "for train_idx, test_idx in kf_iter_train:\n",
    "    folds_train.append((train_idx, test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trs = []; X_cvalids = []\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    X_tr, X_cvalid = train.iloc[train_indices], train.iloc[cvalid_indices]\n",
    "    y_tr, y_cvalid = train['MIS_Status'].iloc[train_indices], train['MIS_Status'].iloc[cvalid_indices]\n",
    "    for col in target_encode_cols:\n",
    "        X_tr = target_encode_test(X_cvalid, y_cvalid, X_tr, col)\n",
    "        X_cvalid = target_encode_test(X_tr, y_tr, X_cvalid, col)\n",
    "    # for col in target_encode_smooth_cols:\n",
    "    #     X_tr = target_encode_smooth_test(X_cvalid, y_cvalid, X_tr, col)\n",
    "    #     X_cvalid = target_encode_smooth_test(X_tr, y_tr, X_cvalid, col)\n",
    "    X_tr = target_encode_cols_smooth_test(X_cvalid, y_cvalid, X_tr, [\"longitude\", \"latitude\"], \"location\")\n",
    "    X_cvalid = target_encode_cols_smooth_test(X_tr, y_tr, X_cvalid, [\"longitude\", \"latitude\"], \"location\")\n",
    "    X_trs.append(X_tr[all_cols])\n",
    "    X_cvalids.append(X_cvalid[all_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold No. =  0\n",
      "[10]\tvalid_0's Macrof1: 0.67046\n",
      "[20]\tvalid_0's Macrof1: 0.672227\n",
      "[30]\tvalid_0's Macrof1: 0.670903\n",
      "[40]\tvalid_0's Macrof1: 0.673336\n",
      "[50]\tvalid_0's Macrof1: 0.6725\n",
      "[60]\tvalid_0's Macrof1: 0.67226\n",
      "[70]\tvalid_0's Macrof1: 0.671062\n",
      "[80]\tvalid_0's Macrof1: 0.670736\n",
      "[90]\tvalid_0's Macrof1: 0.670406\n",
      "[100]\tvalid_0's Macrof1: 0.670241\n",
      "now caluculating MacroF1 values .....\n",
      "fold 0 MacroF1: 0.6733355408983948\n",
      "fold No. =  1\n",
      "[10]\tvalid_0's Macrof1: 0.682511\n",
      "[20]\tvalid_0's Macrof1: 0.682325\n",
      "[30]\tvalid_0's Macrof1: 0.684552\n",
      "[40]\tvalid_0's Macrof1: 0.681769\n",
      "[50]\tvalid_0's Macrof1: 0.683092\n",
      "[60]\tvalid_0's Macrof1: 0.683976\n",
      "[70]\tvalid_0's Macrof1: 0.683144\n",
      "[80]\tvalid_0's Macrof1: 0.683463\n",
      "[90]\tvalid_0's Macrof1: 0.682923\n",
      "[100]\tvalid_0's Macrof1: 0.681539\n",
      "now caluculating MacroF1 values .....\n",
      "fold 1 MacroF1: 0.6845524993474289\n",
      "fold No. =  2\n",
      "[10]\tvalid_0's Macrof1: 0.678195\n",
      "[20]\tvalid_0's Macrof1: 0.677253\n",
      "[30]\tvalid_0's Macrof1: 0.680578\n",
      "[40]\tvalid_0's Macrof1: 0.6821\n",
      "[50]\tvalid_0's Macrof1: 0.682219\n",
      "[60]\tvalid_0's Macrof1: 0.682531\n",
      "[70]\tvalid_0's Macrof1: 0.681507\n",
      "[80]\tvalid_0's Macrof1: 0.682345\n",
      "[90]\tvalid_0's Macrof1: 0.683953\n",
      "[100]\tvalid_0's Macrof1: 0.683594\n",
      "now caluculating MacroF1 values .....\n",
      "fold 2 MacroF1: 0.6849859714144189\n",
      "fold No. =  3\n",
      "[10]\tvalid_0's Macrof1: 0.68041\n",
      "[20]\tvalid_0's Macrof1: 0.678804\n",
      "[30]\tvalid_0's Macrof1: 0.677805\n",
      "[40]\tvalid_0's Macrof1: 0.679653\n",
      "[50]\tvalid_0's Macrof1: 0.679762\n",
      "[60]\tvalid_0's Macrof1: 0.679287\n",
      "[70]\tvalid_0's Macrof1: 0.678141\n",
      "[80]\tvalid_0's Macrof1: 0.67921\n",
      "[90]\tvalid_0's Macrof1: 0.679591\n",
      "[100]\tvalid_0's Macrof1: 0.67966\n",
      "now caluculating MacroF1 values .....\n",
      "fold 3 MacroF1: 0.6812022318001724\n",
      "fold No. =  4\n",
      "[10]\tvalid_0's Macrof1: 0.675018\n",
      "[20]\tvalid_0's Macrof1: 0.673789\n",
      "[30]\tvalid_0's Macrof1: 0.674564\n",
      "[40]\tvalid_0's Macrof1: 0.674885\n",
      "[50]\tvalid_0's Macrof1: 0.674489\n",
      "[60]\tvalid_0's Macrof1: 0.675809\n",
      "[70]\tvalid_0's Macrof1: 0.674994\n",
      "[80]\tvalid_0's Macrof1: 0.676009\n",
      "[90]\tvalid_0's Macrof1: 0.675611\n",
      "[100]\tvalid_0's Macrof1: 0.675029\n",
      "now caluculating MacroF1 values .....\n",
      "fold 4 MacroF1: 0.6768916607542323\n"
     ]
    }
   ],
   "source": [
    "valid_scores = []\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "boosters = []\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    X_tr = X_trs[fold]\n",
    "    X_cvalid = X_cvalids[fold]\n",
    "    y_tr = train['MIS_Status'].iloc[train_indices]\n",
    "    y_cvalid = train['MIS_Status'].iloc[cvalid_indices]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_tr[all_cols], y_tr)\n",
    "    lgb_eval = lgb.Dataset(X_cvalid[all_cols], y_cvalid)\n",
    "\n",
    "    print(\"fold No. = \", fold)\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'None',  # Use custom to use the custom metric for evaluation\n",
    "    'verbose': -1,\n",
    "    'learning_rate':0.1,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets = lgb_eval,\n",
    "        num_boost_round = 100,\n",
    "        feval = Macrof1,\n",
    "        callbacks=[lgb.log_evaluation(10)],\n",
    "    )\n",
    "    \n",
    "    print(\"now caluculating MacroF1 values .....\")\n",
    "    name, score, _ = Macrof1(model.predict(X_cvalid), lgb_eval)\n",
    "    print(f'fold {fold} MacroF1: {score}')\n",
    "    valid_scores.append(score)\n",
    "\n",
    "    boosters.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6733355408983948,\n",
       " 0.6845524993474289,\n",
       " 0.6849859714144189,\n",
       " 0.6812022318001724,\n",
       " 0.6768916607542323]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare submission\n",
    "#### target encoding for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encode_cols = ['Sector', 'State', 'BankState', 'FranchiseCode']\n",
    "for column in retained_cat_cols:\n",
    "    test[column] = test[column].astype(\"category\")\n",
    "# We can simply use training data to encode the test data\n",
    "for col in target_encode_cols:\n",
    "    test = target_encode_test(train, train['MIS_Status'], test, col)\n",
    "# for smooth data:\n",
    "# test =target_encode_smooth_test(train, train['MIS_Status'], test, \"longitude\")\n",
    "# test =target_encode_smooth_test(train, train['MIS_Status'], test, \"latitude\")\n",
    "test =target_encode_cols_smooth_test(train, train['MIS_Status'], test, [\"longitude\", \"latitude\"], name=\"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare submission\n",
    "pred_average = np.mean([item.predict(test[all_cols]) for item in boosters], axis=0)\n",
    "test_prediction = (pred_average > np.quantile(pred_average, 0.1)).astype(int) # ここはもう少し良い選び方があるはずです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = test_prediction\n",
    "test['prediction'].to_csv('submission_lonlat.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoEmp                          int64\n",
      "CreateJob                      int64\n",
      "RetainedJob                    int64\n",
      "ApprovalFY                     int64\n",
      "DisbursementGross            float64\n",
      "GrAppv                       float64\n",
      "SBA_Appv                     float64\n",
      "NewExist                     float64\n",
      "RevLineCr                     object\n",
      "LowDoc                        object\n",
      "UrbanRural                     int64\n",
      "DisbursementDate_daystamp    float64\n",
      "ApprovalDate_daystamp          int64\n",
      "FranchiseCode1                  bool\n",
      "FranchiseCode0                  bool\n",
      "Sector_target                float64\n",
      "State_target                 float64\n",
      "BankState_target             float64\n",
      "FranchiseCode_target         float64\n",
      "latitude                     float64\n",
      "longitude                    float64\n",
      "location_target              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test[all_cols].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoEmp                           int64\n",
      "CreateJob                       int64\n",
      "RetainedJob                     int64\n",
      "ApprovalFY                      int64\n",
      "DisbursementGross             float64\n",
      "GrAppv                        float64\n",
      "SBA_Appv                      float64\n",
      "NewExist                     category\n",
      "RevLineCr                    category\n",
      "LowDoc                       category\n",
      "UrbanRural                   category\n",
      "DisbursementDate_daystamp     float64\n",
      "ApprovalDate_daystamp           int64\n",
      "FranchiseCode1                   bool\n",
      "FranchiseCode0                   bool\n",
      "Sector_target                 float64\n",
      "State_target                  float64\n",
      "BankState_target              float64\n",
      "FranchiseCode_target          float64\n",
      "latitude                      float64\n",
      "longitude                     float64\n",
      "location_target               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_val[all_cols].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
