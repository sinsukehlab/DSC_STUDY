{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model\n",
    "\n",
    "In this notebook, we create a simple model using LightGBM. The features included in this model are:\n",
    "- all float (or int but not category) variables as it is:\n",
    "    - `RevLineCr`, `NoEmp`, `CreateJob`, `RetainedJob`, `ApprovalFY`. `DisbursementGross`, `GrAppv`, `SBA_Appv`\n",
    "- some categorical variables as it is:\n",
    "    - `NewExist`, `RevLineCr`, `LowDoc`, `UrbanRural`\n",
    "- Some date objects as daystamp:\n",
    "    - `DisbursementDate_daystamp`, `ApprovalDate_daystamp`\n",
    "- Some categorical varibles with coarse labeling:\n",
    "    - `FranchiseCode`(0,1,or others)\n",
    "- Some categorical variables with holdout target encoding:\n",
    "    - `Sector`, `State`, `BankState`\n",
    "- `Longitude`, `Latitude`: holdout target encoded with `HistGradientBoostingClassifier`\n",
    "\n",
    "Note that `City` is not used in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cat_encodings import target_encode_test, target_encode_smooth_test\n",
    "from clean_data import clean_data\n",
    "import os\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "EDITED_DATA_DIR = \"edited_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"), index_col = 0)\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"), index_col = 0)\n",
    "geo_train = pd.read_csv(os.path.join(EDITED_DATA_DIR, \"train_geohash.csv\"), index_col = 0)\n",
    "geo_test = pd.read_csv(os.path.join(EDITED_DATA_DIR, \"test_geohash.csv\"), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "train = clean_data(train)\n",
    "test = clean_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location', 'origin', 'geohash', 'latitude', 'longitude'}\n"
     ]
    }
   ],
   "source": [
    "# columns that are in geo_train but not train\n",
    "print(set(geo_train) - set(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use latitude and longitude col\n",
    "for col in ['latitude', 'longitude']:\n",
    "    train[col] = geo_train[col]\n",
    "    test[col] = geo_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Term                                  int64\n",
       "NoEmp                                 int64\n",
       "NewExist                           category\n",
       "CreateJob                             int64\n",
       "RetainedJob                           int64\n",
       "FranchiseCode                      category\n",
       "RevLineCr                          category\n",
       "LowDoc                             category\n",
       "DisbursementDate             datetime64[ns]\n",
       "MIS_Status                            int64\n",
       "Sector                             category\n",
       "ApprovalDate                 datetime64[ns]\n",
       "ApprovalFY                            int64\n",
       "City                                 object\n",
       "State                                object\n",
       "BankState                            object\n",
       "DisbursementGross                   float64\n",
       "GrAppv                              float64\n",
       "SBA_Appv                            float64\n",
       "UrbanRural                         category\n",
       "DisbursementDate_year               float64\n",
       "DisbursementDate_month              float64\n",
       "DisbursementDate_day                float64\n",
       "DisbursementDate_daystamp           float64\n",
       "ApprovalDate_year                     int32\n",
       "ApprovalDate_month                    int32\n",
       "ApprovalDate_day                      int32\n",
       "ApprovalDate_daystamp                 int64\n",
       "FranchiseCode1                     category\n",
       "FranchiseCode0                     category\n",
       "latitude                            float64\n",
       "longitude                           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns used for training -> all_cols\n",
    "num_cols = ['NoEmp', 'CreateJob', 'RetainedJob', 'ApprovalFY', 'DisbursementGross', 'GrAppv', 'SBA_Appv']\n",
    "retained_cat_cols = ['NewExist', 'RevLineCr', 'LowDoc', 'UrbanRural']\n",
    "timestamp_cols = ['DisbursementDate_daystamp', 'ApprovalDate_daystamp']\n",
    "franchise_cols = ['FranchiseCode1', 'FranchiseCode0']\n",
    "target_encode_cols = ['Sector', 'State', 'BankState']\n",
    "target_encoded_cols = [item + \"_target\" for item in target_encode_cols]\n",
    "target_encode_smooth_cols = [\"longitude\", \"latitude\"]\n",
    "target_encoded_smooth_cols = [item + \"_target\" for item in target_encode_smooth_cols]\n",
    "location_cols = ['latitude', 'longitude']\n",
    "all_cols = num_cols + retained_cat_cols + timestamp_cols + franchise_cols + target_encoded_cols + location_cols + target_encoded_smooth_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, val の分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train,train[\"MIS_Status\"], test_size=0.2, random_state=42, stratify=train['MIS_Status']) # stratifyした方がいいかも"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding for valid data\n",
    "\n",
    "trainの値を使って，testのtarget encodingをします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encode_cols = ['Sector', 'State', 'BankState']\n",
    "    \n",
    "# We can simply use training data to encode the test data\n",
    "for col in target_encode_cols:\n",
    "    X_val = target_encode_test(X_train, y_train, X_val, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for smooth data:\n",
    "X_val =target_encode_smooth_test(X_train, y_train, X_val, \"longitude\")\n",
    "X_val =target_encode_smooth_test(X_train, y_train, X_val, \"latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding for train data\n",
    "\n",
    "CVの分け方と合うように，target encodingをしていきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1000)\n",
    "# for train\n",
    "kf_iter_train = kf.split(X_train, y_train)\n",
    "\n",
    "# create list of indices for training / test data to use for holdout target encoding\n",
    "folds_train = []\n",
    "for train_idx, test_idx in kf_iter_train:\n",
    "    folds_train.append((train_idx, test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trs = []; X_cvalids = []\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    X_tr, X_cvalid = X_train.iloc[train_indices], X_train.iloc[cvalid_indices]\n",
    "    y_tr, y_cvalid = y_train.iloc[train_indices], y_train.iloc[cvalid_indices]\n",
    "    for col in target_encode_cols:\n",
    "        X_tr = target_encode_test(X_cvalid, y_cvalid, X_tr, col)\n",
    "        X_cvalid = target_encode_test(X_tr, y_tr, X_cvalid, col)\n",
    "    for col in target_encode_smooth_cols:\n",
    "        X_tr = target_encode_smooth_test(X_cvalid, y_cvalid, X_tr, col)\n",
    "        X_cvalid = target_encode_smooth_test(X_tr, y_tr, X_cvalid, col)\n",
    "    X_trs.append(X_tr[all_cols])\n",
    "    X_cvalids.append(X_cvalid[all_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro F1 Score (with threshold included in the metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  f1_score\n",
    "def Macrof1(preds, eval_dataset):\n",
    "    y_true = eval_dataset.get_label()\n",
    "    max_score =0\n",
    "    for th in np.linspace(0.2,0.9,100):\n",
    "        y_pred = (preds>th).astype(int)\n",
    "        score = f1_score(y_true, y_pred, average='macro')\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "    return 'Macrof1', max_score, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold No. =  0\n",
      "[10]\tvalid_0's Macrof1: 0.67221\n",
      "[20]\tvalid_0's Macrof1: 0.671485\n",
      "[30]\tvalid_0's Macrof1: 0.670574\n",
      "[40]\tvalid_0's Macrof1: 0.672791\n",
      "[50]\tvalid_0's Macrof1: 0.676263\n",
      "[60]\tvalid_0's Macrof1: 0.676787\n",
      "[70]\tvalid_0's Macrof1: 0.677848\n",
      "[80]\tvalid_0's Macrof1: 0.679993\n",
      "[90]\tvalid_0's Macrof1: 0.678207\n",
      "[100]\tvalid_0's Macrof1: 0.680928\n",
      "now caluculating MacroF1 values .....\n",
      "fold 0 MacroF1: 0.6815196565893237\n",
      "fold No. =  1\n",
      "[10]\tvalid_0's Macrof1: 0.676689\n",
      "[20]\tvalid_0's Macrof1: 0.676277\n",
      "[30]\tvalid_0's Macrof1: 0.681054\n",
      "[40]\tvalid_0's Macrof1: 0.682928\n",
      "[50]\tvalid_0's Macrof1: 0.681497\n",
      "[60]\tvalid_0's Macrof1: 0.680838\n",
      "[70]\tvalid_0's Macrof1: 0.680375\n",
      "[80]\tvalid_0's Macrof1: 0.678758\n",
      "[90]\tvalid_0's Macrof1: 0.678758\n",
      "[100]\tvalid_0's Macrof1: 0.681378\n",
      "now caluculating MacroF1 values .....\n",
      "fold 1 MacroF1: 0.6842781069276336\n",
      "fold No. =  2\n",
      "[10]\tvalid_0's Macrof1: 0.67464\n",
      "[20]\tvalid_0's Macrof1: 0.676558\n",
      "[30]\tvalid_0's Macrof1: 0.678082\n",
      "[40]\tvalid_0's Macrof1: 0.678405\n",
      "[50]\tvalid_0's Macrof1: 0.677758\n",
      "[60]\tvalid_0's Macrof1: 0.678019\n",
      "[70]\tvalid_0's Macrof1: 0.678773\n",
      "[80]\tvalid_0's Macrof1: 0.677868\n",
      "[90]\tvalid_0's Macrof1: 0.676522\n",
      "[100]\tvalid_0's Macrof1: 0.676277\n",
      "now caluculating MacroF1 values .....\n",
      "fold 2 MacroF1: 0.6790552659369395\n",
      "fold No. =  3\n",
      "[10]\tvalid_0's Macrof1: 0.676068\n",
      "[20]\tvalid_0's Macrof1: 0.672837\n",
      "[30]\tvalid_0's Macrof1: 0.673739\n",
      "[40]\tvalid_0's Macrof1: 0.673597\n",
      "[50]\tvalid_0's Macrof1: 0.672533\n",
      "[60]\tvalid_0's Macrof1: 0.672166\n",
      "[70]\tvalid_0's Macrof1: 0.674354\n",
      "[80]\tvalid_0's Macrof1: 0.674491\n",
      "[90]\tvalid_0's Macrof1: 0.675231\n",
      "[100]\tvalid_0's Macrof1: 0.674157\n",
      "now caluculating MacroF1 values .....\n",
      "fold 3 MacroF1: 0.6769504600363021\n",
      "fold No. =  4\n",
      "[10]\tvalid_0's Macrof1: 0.683766\n",
      "[20]\tvalid_0's Macrof1: 0.684112\n",
      "[30]\tvalid_0's Macrof1: 0.686729\n",
      "[40]\tvalid_0's Macrof1: 0.685311\n",
      "[50]\tvalid_0's Macrof1: 0.683138\n",
      "[60]\tvalid_0's Macrof1: 0.684048\n",
      "[70]\tvalid_0's Macrof1: 0.683003\n",
      "[80]\tvalid_0's Macrof1: 0.684114\n",
      "[90]\tvalid_0's Macrof1: 0.686309\n",
      "[100]\tvalid_0's Macrof1: 0.687559\n",
      "now caluculating MacroF1 values .....\n",
      "fold 4 MacroF1: 0.687558997253426\n"
     ]
    }
   ],
   "source": [
    "valid_scores = []\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "boosters = []\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    X_tr = X_trs[fold]\n",
    "    X_cvalid = X_cvalids[fold]\n",
    "    y_tr = y_train.iloc[train_indices]\n",
    "    y_cvalid = y_train.iloc[cvalid_indices]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_tr[all_cols], y_tr)\n",
    "    lgb_eval = lgb.Dataset(X_cvalid[all_cols], y_cvalid)\n",
    "\n",
    "    print(\"fold No. = \", fold)\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'None',  # Use custom to use the custom metric for evaluation\n",
    "    'verbose': -1,\n",
    "    'learning_rate':0.1,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets = lgb_eval,\n",
    "        num_boost_round = 100,\n",
    "        feval = Macrof1,\n",
    "        callbacks=[lgb.log_evaluation(10)],\n",
    "    )\n",
    "    \n",
    "    print(\"now caluculating MacroF1 values .....\")\n",
    "    name, score, _ = Macrof1(model.predict(X_cvalid), lgb_eval)\n",
    "    print(f'fold {fold} MacroF1: {score}')\n",
    "    valid_scores.append(score)\n",
    "\n",
    "    boosters.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6837238209415563,\n",
       " 0.68682229501981,\n",
       " 0.6807903189433329,\n",
       " 0.6778777267457856,\n",
       " 0.6851297909188753]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check scores with valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_average = np.mean([item.predict(X_val[all_cols]) for item in boosters], axis=0)\n",
    "test_prediction = (pred_average > np.quantile(pred_average, 0.1)).astype(int) # ここはもう少し良い選び方があるはずです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741911970338366"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, test_prediction, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB training with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1000)\n",
    "# for train\n",
    "kf_iter_train = kf.split(train, train['MIS_Status'])\n",
    "\n",
    "# create list of indices for training / test data to use for holdout target encoding\n",
    "folds_train = []\n",
    "for train_idx, test_idx in kf_iter_train:\n",
    "    folds_train.append((train_idx, test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trs = []; X_cvalids = []\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    X_tr, X_cvalid = train.iloc[train_indices], train.iloc[cvalid_indices]\n",
    "    y_tr, y_cvalid = train['MIS_Status'].iloc[train_indices], train['MIS_Status'].iloc[cvalid_indices]\n",
    "    for col in target_encode_cols:\n",
    "        X_tr = target_encode_test(X_cvalid, y_cvalid, X_tr, col)\n",
    "        X_cvalid = target_encode_test(X_tr, y_tr, X_cvalid, col)\n",
    "    for col in target_encode_smooth_cols:\n",
    "        X_tr = target_encode_smooth_test(X_cvalid, y_cvalid, X_tr, col)\n",
    "        X_cvalid = target_encode_smooth_test(X_tr, y_tr, X_cvalid, col)\n",
    "    X_trs.append(X_tr[all_cols])\n",
    "    X_cvalids.append(X_cvalid[all_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold No. =  0\n",
      "[10]\tvalid_0's Macrof1: 0.666318\n",
      "[20]\tvalid_0's Macrof1: 0.671807\n",
      "[30]\tvalid_0's Macrof1: 0.671669\n",
      "[40]\tvalid_0's Macrof1: 0.670473\n",
      "[50]\tvalid_0's Macrof1: 0.67403\n",
      "[60]\tvalid_0's Macrof1: 0.672121\n",
      "[70]\tvalid_0's Macrof1: 0.670829\n",
      "[80]\tvalid_0's Macrof1: 0.670472\n",
      "[90]\tvalid_0's Macrof1: 0.67274\n",
      "[100]\tvalid_0's Macrof1: 0.672559\n",
      "now caluculating MacroF1 values .....\n",
      "fold 0 MacroF1: 0.674030193706318\n",
      "fold No. =  1\n",
      "[10]\tvalid_0's Macrof1: 0.681439\n",
      "[20]\tvalid_0's Macrof1: 0.687257\n",
      "[30]\tvalid_0's Macrof1: 0.688046\n",
      "[40]\tvalid_0's Macrof1: 0.688245\n",
      "[50]\tvalid_0's Macrof1: 0.68713\n",
      "[60]\tvalid_0's Macrof1: 0.685986\n",
      "[70]\tvalid_0's Macrof1: 0.686127\n",
      "[80]\tvalid_0's Macrof1: 0.686882\n",
      "[90]\tvalid_0's Macrof1: 0.686113\n",
      "[100]\tvalid_0's Macrof1: 0.685705\n",
      "now caluculating MacroF1 values .....\n",
      "fold 1 MacroF1: 0.6900889332082562\n",
      "fold No. =  2\n",
      "[10]\tvalid_0's Macrof1: 0.674238\n",
      "[20]\tvalid_0's Macrof1: 0.677406\n",
      "[30]\tvalid_0's Macrof1: 0.680719\n",
      "[40]\tvalid_0's Macrof1: 0.681098\n",
      "[50]\tvalid_0's Macrof1: 0.680912\n",
      "[60]\tvalid_0's Macrof1: 0.682525\n",
      "[70]\tvalid_0's Macrof1: 0.679466\n",
      "[80]\tvalid_0's Macrof1: 0.677669\n",
      "[90]\tvalid_0's Macrof1: 0.67758\n",
      "[100]\tvalid_0's Macrof1: 0.679619\n",
      "now caluculating MacroF1 values .....\n",
      "fold 2 MacroF1: 0.6825250507932391\n",
      "fold No. =  3\n",
      "[10]\tvalid_0's Macrof1: 0.675551\n",
      "[20]\tvalid_0's Macrof1: 0.677747\n",
      "[30]\tvalid_0's Macrof1: 0.677604\n",
      "[40]\tvalid_0's Macrof1: 0.678916\n",
      "[50]\tvalid_0's Macrof1: 0.678104\n",
      "[60]\tvalid_0's Macrof1: 0.679017\n",
      "[70]\tvalid_0's Macrof1: 0.677537\n",
      "[80]\tvalid_0's Macrof1: 0.677059\n",
      "[90]\tvalid_0's Macrof1: 0.677019\n",
      "[100]\tvalid_0's Macrof1: 0.677784\n",
      "now caluculating MacroF1 values .....\n",
      "fold 3 MacroF1: 0.679484572257977\n",
      "fold No. =  4\n",
      "[10]\tvalid_0's Macrof1: 0.671844\n",
      "[20]\tvalid_0's Macrof1: 0.673242\n",
      "[30]\tvalid_0's Macrof1: 0.672547\n",
      "[40]\tvalid_0's Macrof1: 0.671223\n",
      "[50]\tvalid_0's Macrof1: 0.670987\n",
      "[60]\tvalid_0's Macrof1: 0.671524\n",
      "[70]\tvalid_0's Macrof1: 0.672935\n",
      "[80]\tvalid_0's Macrof1: 0.67333\n",
      "[90]\tvalid_0's Macrof1: 0.674144\n",
      "[100]\tvalid_0's Macrof1: 0.672408\n",
      "now caluculating MacroF1 values .....\n",
      "fold 4 MacroF1: 0.6751655935736369\n"
     ]
    }
   ],
   "source": [
    "valid_scores = []\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "boosters = []\n",
    "for fold, (train_indices, cvalid_indices) in enumerate(folds_train):\n",
    "    X_tr = X_trs[fold]\n",
    "    X_cvalid = X_cvalids[fold]\n",
    "    y_tr = train['MIS_Status'].iloc[train_indices]\n",
    "    y_cvalid = train['MIS_Status'].iloc[cvalid_indices]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_tr[all_cols], y_tr)\n",
    "    lgb_eval = lgb.Dataset(X_cvalid[all_cols], y_cvalid)\n",
    "\n",
    "    print(\"fold No. = \", fold)\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'None',  # Use custom to use the custom metric for evaluation\n",
    "    'verbose': -1,\n",
    "    'learning_rate':0.1,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets = lgb_eval,\n",
    "        num_boost_round = 100,\n",
    "        feval = Macrof1,\n",
    "        callbacks=[lgb.log_evaluation(10)],\n",
    "    )\n",
    "    \n",
    "    print(\"now caluculating MacroF1 values .....\")\n",
    "    name, score, _ = Macrof1(model.predict(X_cvalid), lgb_eval)\n",
    "    print(f'fold {fold} MacroF1: {score}')\n",
    "    valid_scores.append(score)\n",
    "\n",
    "    boosters.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.674030193706318,\n",
       " 0.6900889332082562,\n",
       " 0.6825250507932391,\n",
       " 0.679484572257977,\n",
       " 0.6751655935736369]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare submission\n",
    "#### target encoding for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encode_cols = ['Sector', 'State', 'BankState']\n",
    "    \n",
    "# We can simply use training data to encode the test data\n",
    "for col in target_encode_cols:\n",
    "    test = target_encode_test(train, train['MIS_Status'], test, col)\n",
    "# for smooth data:\n",
    "test =target_encode_smooth_test(train, train['MIS_Status'], test, \"longitude\")\n",
    "test =target_encode_smooth_test(train, train['MIS_Status'], test, \"latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare submission\n",
    "pred_average = np.mean([item.predict(test[all_cols]) for item in boosters], axis=0)\n",
    "test_prediction = (pred_average > np.quantile(pred_average, 0.1)).astype(int) # ここはもう少し良い選び方があるはずです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = test_prediction\n",
    "test['prediction'].to_csv('submission_ex.csv', header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
